{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Feature impotance with desidion tree"
      ],
      "metadata": {
        "id": "_J2bqya_JjIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Загрузка набора данных о винах\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Обучение дерева решений и оценка важности признаков\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(X, y)\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "feature_importances\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEapgUuoH6bt",
        "outputId": "5598e6cc-822b-4bb8-d425-51501826d844"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01257056, 0.02560169, 0.        , 0.        , 0.03297845,\n",
              "       0.        , 0.14144668, 0.        , 0.        , 0.03470451,\n",
              "       0.05818509, 0.31204257, 0.38247045])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Первоначальная оценка модели дерева решений без выбора признаков\n",
        "initial_score = np.mean(cross_val_score(DecisionTreeClassifier(random_state=0), X, y, cv=5))\n",
        "\n",
        "# Оценка модели дерева решений, используя признаки, выбранные деревом решений\n",
        "selected_X_by_tree = X[:, feature_importances > np.mean(feature_importances)]\n",
        "score_with_tree_selected_features = np.mean(cross_val_score(DecisionTreeClassifier(random_state=0), selected_X_by_tree, y, cv=5))\n",
        "\n",
        "print(\"No features selection: \", initial_score)\n",
        "print(\"Desidion tree feature selection: \", score_with_tree_selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUC9F-AWIxWG",
        "outputId": "9265afa1-918a-4eb2-e2c1-3fe70e8be6d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No features selection:  0.8876190476190475\n",
            "Desidion tree feature selection:  0.8996825396825396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Алгоритм ADD-DEL (добавление-удаление)\n",
        "\n",
        "Алгоритм ADD-DEL (добавление-удаление) — это эвристический метод, используемый в машинном обучении и оптимизации для выбора признаков или переменных в модели. Он работает в двух основных этапах:\n",
        "\n",
        "Этап добавления (ADD): Начиная с пустого набора признаков, алгоритм последовательно добавляет признаки, которые наиболее улучшают производительность модели. На каждом шаге алгоритм оценивает, как добавление каждого неиспользуемого признака повлияет на модель, и выбирает тот, который дает наибольшее улучшение. Этот процесс продолжается до тех пор, пока добавление новых признаков не перестанет улучшать модель или пока не будут учтены все признаки.\n",
        "\n",
        "\n",
        "Этап удаления (DEL): После того, как добавлены все признаки, алгоритм переходит к этапу удаления. На этом этапе он последовательно удаляет признаки, которые меньше всего влияют на производительность модели или даже ухудшают ее. На каждом шаге алгоритм оценивает влияние удаления каждого признака и удаляет тот, чье удаление наиболее положительно сказывается на модели. Этот процесс продолжается до тех пор, пока удаление признаков не начнет ухудшать модель.\n",
        "Эти два этапа могут чередоваться, пока не будет найден оптимальный набор признаков. Алгоритм ADD-DEL особенно полезен, когда есть большое количество потенциальных признаков, и нужно определить, какие из них наиболее важны для моделирования."
      ],
      "metadata": {
        "id": "3QGQ_hPBIQpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkcYWfapH1Os",
        "outputId": "8f94c252-74f3-4673-8a0d-39a0e5af3a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  [0, 1, 3, 4, 5, 6, 9, 10]\n",
            "ADD-DEL selection score:  0.961111111111111\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def add_del_feature_selection_dt(X, y, feature_importances, initial_features=[], threshold=0.01):\n",
        "    \"\"\"\n",
        "    ADD-DEL Feature Selection Algorithm using Decision Tree feature importances\n",
        "    :param X: Feature set\n",
        "    :param y: Target variable\n",
        "    :param feature_importances: Importance of features as determined by a decision tree\n",
        "    :param initial_features: List of initially selected features (indices)\n",
        "    :param threshold: Improvement threshold for feature addition/removal\n",
        "    :return: List of selected feature indices\n",
        "    \"\"\"\n",
        "    selected_features = list(initial_features)\n",
        "    features = list(range(X.shape[1]))\n",
        "    improvement = True\n",
        "\n",
        "    while improvement:\n",
        "        improvement = False\n",
        "\n",
        "        # ADD Step\n",
        "        for feature in set(features) - set(selected_features):\n",
        "            current_features = selected_features + [feature]\n",
        "            score = np.mean(cross_val_score(DecisionTreeClassifier(random_state=0), X[:, current_features], y, cv=5))\n",
        "            if score - threshold > 0.01:  # Use a fixed threshold for improvement\n",
        "                selected_features.append(feature)\n",
        "                threshold = score\n",
        "                improvement = True\n",
        "\n",
        "        # DEL Step\n",
        "        for feature in selected_features:\n",
        "            if feature_importances[feature] < np.mean(feature_importances):  # Consider removing less important features\n",
        "                current_features = list(selected_features)\n",
        "                current_features.remove(feature)\n",
        "                score = np.mean(cross_val_score(DecisionTreeClassifier(random_state=0), X[:, current_features], y, cv=5))\n",
        "                if score - threshold > 0.01:\n",
        "                    selected_features.remove(feature)\n",
        "                    threshold = score\n",
        "                    improvement = True\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "# Выбор признаков с помощью алгоритма ADD-DEL\n",
        "selected_features = add_del_feature_selection_dt(X, y, feature_importances)\n",
        "\n",
        "# Обучение и оценка модели дерева решений на выбранных признаках\n",
        "selected_X = X[:, selected_features]\n",
        "final_model = DecisionTreeClassifier(random_state=0)\n",
        "final_score = np.mean(cross_val_score(final_model, selected_X, y, cv=5))\n",
        "\n",
        "print(\"Features: \", selected_features)\n",
        "print(\"ADD-DEL selection score: \", final_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature impotance with permutation"
      ],
      "metadata": {
        "id": "waCZZUPLJdFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Обучение модели дерева решений на всех признаках\n",
        "model.fit(X, y)\n",
        "\n",
        "# Вычисление важности признаков с помощью перестановок\n",
        "perm_importance = permutation_importance(model, X, y, n_repeats=100, random_state=0)\n",
        "\n",
        "perm_importance.importances_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIA_gHd0JOXy",
        "outputId": "cfef1583-1fa4-4794-a880-de59de58f624"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02275281, 0.02342697, 0.        , 0.        , 0.01848315,\n",
              "       0.        , 0.39842697, 0.        , 0.        , 0.02702247,\n",
              "       0.05747191, 0.07539326, 0.13674157])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот ключевые выводы из этих результатов:\n",
        "\n",
        "Некоторые признаки, такие как 6-й (средняя важность около 0.408), 12-й (0.133), 11-й (0.075), и 10-й (0.058), имеют значительное влияние на производительность модели. Это указывает на их высокую важность для принятия решений.\n",
        "Другие признаки имеют гораздо меньшую важность, а некоторые из них, как видно, не оказывают значительного влияния на производительность модели (например, признаки 2, 3, 5, 7, 8)."
      ],
      "metadata": {
        "id": "qLuCp65IJ4Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nW7FkrovJ45n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}